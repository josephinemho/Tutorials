{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "1. Clean and transform data\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Handle imbalanced classes\n",
    "4. **Modeling & evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting decision boundaries\n",
    "Oversampling takes observed rarae samples and applies boostrapping to generate new random data based on a distribution function. If cross-validation is applied after over-sampling, we are basically overfitting our model to a specific artificial boostrapping result. \n",
    "\n",
    "I suspect there is are better ways to handle class imbalance that I have not yet explored. In the interest of time, I will stop here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = joblib.load('../work/data/X_train')\n",
    "y_train = joblib.load('../work/data/y_train')\n",
    "X_train_resampled = joblib.load('../work/data/X_train_resampled')\n",
    "y_train_resampled = joblib.load('../work/data/y_train_resampled')\n",
    "X_test = joblib.load('../work/data/X_test')\n",
    "y_test = joblib.load('../work/data/y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Draws a line (hyperplane) between different classes of points. The further a point is from the boundary line, the more its score (estimate) increases (nearing 0 or 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Evaluation:\n",
    "    def __init__(self):\n",
    "        self.name = name\n",
    "    \n",
    "    def fit_model(estimator, X, y):\n",
    "        start = datetime.now()\n",
    "        model = estimator\n",
    "        model.fit(X, y)\n",
    "        print(\"Time: \", datetime.now() - start)\n",
    "        return model\n",
    "    \n",
    "    def score_model(model, X, y):\n",
    "        prediction = model.predict(X)\n",
    "        print(\"Accuracy Score: \", model.score(X, y))\n",
    "        print(\"F1 Score: \", f1_score(y, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:00.449208\n",
      "Accuracy Score:  0.904200915687\n",
      "F1 Score:  0.0105088495575\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on resampled data, with varying values of C\n",
    "\n",
    "lr1 = Model_Evaluation.fit_model(LogisticRegression(C=0.01), X_train_resampled, y_train_resampled)\n",
    "Model_Evaluation.score_model(lr1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:00.450063\n",
      "Accuracy Score:  0.904227690166\n",
      "F1 Score:  0.0105117565698\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on resampled data, with varying values of C\n",
    "\n",
    "lr1 = Model_Evaluation.fit_model(LogisticRegression(C=1), X_train_resampled, y_train_resampled)\n",
    "Model_Evaluation.score_model(lr1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:00.452244\n",
      "Accuracy Score:  0.904227690166\n",
      "F1 Score:  0.0105117565698\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on resampled data, with varying values of C\n",
    "\n",
    "lr1 = Model_Evaluation.fit_model(LogisticRegression(C=100), X_train_resampled, y_train_resampled)\n",
    "Model_Evaluation.score_model(lr1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:00.207569\n",
      "Accuracy Score:  0.999357412514\n",
      "F1 Score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on non-resampled data\n",
    "\n",
    "lr2 = Model_Evaluation.fit_model(LogisticRegression(C=0.01), X_train, y_train)\n",
    "Model_Evaluation.score_model(lr2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision = TP/(TP+FP) so if predictor doesn't predicts positive class at all - precision is 0.\n",
    "\n",
    "recall = TP/(TP+FN), in case if predictor doesn't predict positive class - TP is 0 - recall is 0.\n",
    "\n",
    "So now you are dividing 0/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "{0}\n"
     ]
    }
   ],
   "source": [
    "# The model isn't predicting Positives, so there's no F-score to calculate. \n",
    "# C=0.01 is not enough regularization (penalty) strength, so our model is too overfit.\n",
    "\n",
    "my_model = LogisticRegression(C=0.01)\n",
    "my_model.fit(X_train, y_train)\n",
    "prediction = my_model.predict(X_test)\n",
    "print(set(y_test))\n",
    "print(set(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:00.298089\n",
      "Accuracy Score:  0.999357412514\n",
      "F1 Score:  0.0769230769231\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on non-resampled data\n",
    "\n",
    "lr2 = Model_Evaluation.fit_model(LogisticRegression(C=1), X_train, y_train)\n",
    "Model_Evaluation.score_model(lr2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:00.318385\n",
      "Accuracy Score:  0.999330638036\n",
      "F1 Score:  0.0740740740741\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on non-resampled data\n",
    "\n",
    "lr2 = Model_Evaluation.fit_model(LogisticRegression(C=100), X_train, y_train)\n",
    "Model_Evaluation.score_model(lr2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Recursively subdivides the instance space into finer and finer subregions until it is all one class (or good enough). New instances start at the root node and takes the appropriate path until it reaches a lead node, which determines the classification by checking the classes of the training instances that reached that leaf, and the majority determines the class. For that leaf, the score is calculated by:\n",
    "\n",
    "<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\frac{majority&space;instances}{(majority&space;instances&space;&plus;&space;minority&space;instances)&space;}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\frac{majority&space;instances}{(majority&space;instances&space;&plus;&space;minority&space;instances)&space;}\" title=\"\\frac{majority instances}{(majority instances + minority instances) }\" /></a>\n",
    "\n",
    "When using scikit-learn's DecisionTreeClassifier, always set min_samples_leaf to something like 5 or 10. Its default value of 1 is useless and is guaranteed to overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:00.054830\n",
      "Accuracy Score:  0.856006854267\n",
      "F1 Score:  0.00296625880608\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree on resampled data\n",
    "\n",
    "dt1 = Model_Evaluation.fit_model(DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, max_features=1), X_train_resampled, y_train_resampled)\n",
    "Model_Evaluation.score_model(dt1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:00.536202\n",
      "Accuracy Score:  0.857640097459\n",
      "F1 Score:  0.00561062277913\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree on resampled data\n",
    "\n",
    "dt1 = Model_Evaluation.fit_model(DecisionTreeClassifier(max_depth=5), X_train_resampled, y_train_resampled)\n",
    "Model_Evaluation.score_model(dt1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:00.161170\n",
      "Accuracy Score:  0.999223540122\n",
      "F1 Score:  0.0645161290323\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree on non-resampled data\n",
    "\n",
    "dt1 = Model_Evaluation.fit_model(DecisionTreeClassifier(max_depth=5), X_train, y_train)\n",
    "Model_Evaluation.score_model(dt1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:05.435138\n",
      "Accuracy Score:  0.998902246379\n",
      "F1 Score:  0.046511627907\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on resampled data\n",
    "\n",
    "rf1 = Model_Evaluation.fit_model(RandomForestClassifier, X_train_resampled, y_train_resampled)\n",
    "Model_Evaluation.score_model(rf1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:01.827316\n",
      "Accuracy Score:  0.999223540122\n",
      "F1 Score:  0.0645161290323\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on non-resampled data\n",
    "\n",
    "rf2 = Model_Evaluation.fit_model(RandomForestClassifier, X_train, y_train)\n",
    "Model_Evaluation.score_model(rf2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor\n",
    "If for example, `k=5`, for every new instance, 5 of its nearest neighbors are randomly selected and some function like majority is applied to the five neighbors. To assign a score, divide the number of positive instances by the total and return the fraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN on resampled data\n",
    "\n",
    "kn1 = Model_Evaluation.fit_model(KNeighborsClassifier(n_neighbors=2), X_train_resampled, y_train_resampled)\n",
    "Model_Evaluation.score_model(kn1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:02:40.271168\n",
      "Accuracy Score:  0.992877988701\n",
      "F1 Score:  0.029197080292\n"
     ]
    }
   ],
   "source": [
    "# COMPARE\n",
    "\n",
    "kn1 = Model_Evaluation.fit_model(KNeighborsClassifier(n_neighbors=2), X_train_resampled, y_train_resampled)\n",
    "Model_Evaluation.score_model(kn1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN on non-resampled data\n",
    "\n",
    "kn1 = Model_Evaluation.fit_model(KNeighborsClassifier(n_neighbors=2), X_train, y_train)\n",
    "Model_Evaluation.score_model(kn1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:00:44.031340\n",
      "Accuracy Score:  0.999303863557\n",
      "F1 Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "# COMPARE\n",
    "\n",
    "kn1 = Model_Evaluation.fit_model(KNeighborsClassifier(n_neighbors=2), X_train, y_train)\n",
    "Model_Evaluation.score_model(kn1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our best model: Decision Tree on non-resampled data, without GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../work/best_model.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
